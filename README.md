My HW1 answers.
模型构建和训练步骤：
    首先使用一个类定义全连接层FullyConnectedLayer，输入参数包括输入的神经元个数和输出的神经元个数，
    这个类中定义参数初始化方法、前向传播计算方法、反向传播计算方法以及使用SGD梯度更新的方法；
    然后定义激活函数层ReLULayer，最后定义Softmax层用来输出十个类的类别，同时在softmax层定义交叉熵损失计算方法；

    通过MNIST_MLP类来将各个层连接起来，构建一个两层的神经网络，这个类中包含加载mnist数据集方法、保存以及加载模型的方法，
    同时训练方法和测试方法也都定义在这个类中，学习率更新时采用每两个epoch学习率衰减一半的策略；

Code解释：
    模型的构建：model.py 主要完成了作业要求中的：激活函数；反向传播，loss 以及梯度的计算；学习率下降策略； L2 正则化；优化器 SGD
    参数查找、模型训练和模型保存：search.py 和 train.py 主要完成了作业要求中的：参数查找：学习率，隐藏层大小，正则化强度；模型训练；保 存模型；可视化训练的 loss 曲线
    测试模型并获得结果：test.py 主要完成了作业要求中的：导入模型，用经过参数查找后的模型进行测试，输出分类精度； 可视化网络参数；可视化测试的 loss 曲线，测试的 accuracy 曲线
    
    参数查找到的最优参数是：隐藏层使用128个神经元，学习率使用0.001， 正则化系数使用0.1